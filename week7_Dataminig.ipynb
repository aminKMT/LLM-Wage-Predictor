{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EKXgkjKln6LA0XG48a8Qe3ToMIgYB9yy",
      "authorship_tag": "ABX9TyPt+Qp7+AtsCyqgonmpU/Wz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminKMT/LLM-Wage-Predictor/blob/main/week7_Dataminig.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Mining for Wage Dataset"
      ],
      "metadata": {
        "id": "B2jOExNa3T5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the excel data:"
      ],
      "metadata": {
        "id": "kVtXA9Ce3bnw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOrFQFHSZZE3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"/W2_CPSwage_Pr.xlsx\", sheet_name=\"CPS wages\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Categorical Data"
      ],
      "metadata": {
        "id": "mH9PTkIZ3fuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cols in df.columns:\n",
        "  if cols in ('south', 'Gender','Union','Race', \"Occup\", \"Sector\", \"Marr\" ):\n",
        "     print(df[cols].value_counts())\n"
      ],
      "metadata": {
        "id": "2fltzJBerbEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorical data cleaning:\n",
        "### Elimination"
      ],
      "metadata": {
        "id": "eqLKV_9U6yUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eliminating wring Gende Type\n",
        "df = df[df.Gender != 'Ale']\n",
        "# eliminating wring Race:\n",
        "df = df[(df.Race != 4) & (df.Race != 5)]"
      ],
      "metadata": {
        "id": "crK2pWmyvhyB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descriptive statistics for non-categorical variables"
      ],
      "metadata": {
        "id": "m08R9wnnLJly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Educ',\t'Experience',\t'Wage', 'Age']].describe()"
      ],
      "metadata": {
        "id": "LVhK7juB8UcI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if any varible has missing varibel(if yes, how many !?):\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DllFIxoGLz2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If you only want to replace missing values in one numeric column\n",
        "df['Wage'].fillna(df['Wage'].mean(), inplace=True)\n",
        "#Fill missing values in all numeric columns\n",
        "#df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# Check the dataframe:\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "aUZN1M5dMgmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handeling years of experience outliers:"
      ],
      "metadata": {
        "id": "39U2XyPYZgD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# creating the histogram before removing outl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(df['Experience'], bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Years of Experience')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lnSlugigYkVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Interquabtile for outlier of years of experience\n",
        "Q1 = df['Experience'].quantile(0.25)\n",
        "Q3 = df['Experience'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define acceptable range\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filter out outliers\n",
        "df_no_outliers = df[(df['Experience'] >= lower_bound) & (df['Experience'] <= upper_bound)]"
      ],
      "metadata": {
        "id": "EZev0sQ6YMfg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the histogram AFTER removing outliers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(df_no_outliers['Experience'], bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Years of Experience')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bvFgCJ7RaInO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert Gender values to number\n",
        "# Making a hash map(Dectionary)\n",
        "map = {\n",
        "    'Female' :1,\n",
        "    'Male' : 0\n",
        "}\n",
        "\n",
        "df_no_outliers['Gender'] = df_no_outliers['Gender'].replace(map)\n",
        "# lets see the column\n",
        "df_no_outliers['Gender']\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QGOvxnssaQoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_outliers['Gender'].value_counts()"
      ],
      "metadata": {
        "id": "rvUEnj-8e7Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multicollinearity\n"
      ],
      "metadata": {
        "id": "T1tKqvx6fZEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "corr = df[['Educ','Experience','Wage', 'Age']].corr()\n",
        "print(corr)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Matrix of Numeric Variables\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y0ZYzUJthNuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 2 datasets\n",
        "df_exp = df2.drop(\"Age\", axis = 1)\n",
        "df_Age = df2.drop(\"Experience\", axis = 1)\n"
      ],
      "metadata": {
        "id": "swUxC7aBlSwc"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.columns"
      ],
      "metadata": {
        "id": "5_CU6HUoo1hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot-Encoding"
      ],
      "metadata": {
        "id": "NOyfAC96m6p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_exp_dummy = pd.get_dummies(df_exp, columns=['Race','Occup', 'Sector'], drop_first=True)\n",
        "df_Age_dummy = pd.get_dummies(df_Age, columns=['Race','Occup', 'Sector'], drop_first=True)"
      ],
      "metadata": {
        "id": "J9kBxuRPfuWS"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check it out!\n",
        "df_Age_dummy.head()"
      ],
      "metadata": {
        "id": "6x6Iv65XoH3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making the model for df_exp_dummy"
      ],
      "metadata": {
        "id": "gzRDga3NpWmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. creating target and independent varibles\n",
        "df_1 = df_exp_dummy.copy()\n",
        "X= df_1.drop(columns = 'Wage')\n",
        "y = df_1['Wage']\n",
        "\n",
        "#2.  split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #seed number =It’s simply a seed number that tells Python to generate the same random results every time you run the code.\n",
        "\n",
        "#3.   fit\n",
        "model = LinearRegression() # Create a LinearRegression object and store it in a variable called model.”\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4 predict & metrics\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"MAE:\", round(mean_absolute_error(y_test, y_pred), 3))\n",
        "print(\"RMSE:\", round(np.sqrt(mean_squared_error(y_test, y_pred)), 3))\n",
        "\n"
      ],
      "metadata": {
        "id": "-vYPZj_boKC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict an Unseen persin's wage\n",
        "Unseen_Person = X_test.iloc[[1]]\n",
        "X_test.iloc[[1]]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-XkbTHWIz8KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict it:\n",
        "Prediction = model.predict(Unseen_Person)\n",
        "print('Predicted wage is','$',round(Prediction[0],2))"
      ],
      "metadata": {
        "id": "ELfrlbLPzA4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Making the model for df_Age_dummy"
      ],
      "metadata": {
        "id": "8CAAYmpj2pHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. creating target and independent varibles\n",
        "df_2 = df_Age_dummy.copy()\n",
        "X= df_2.drop(columns = 'Wage')\n",
        "y = df_2['Wage']\n",
        "\n",
        "#2.  split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #seed number =It’s simply a seed number that tells Python to generate the same random results every time you run the code.\n",
        "\n",
        "#3.   fit\n",
        "model2 = LinearRegression() # Create a LinearRegression object and store it in a variable called model.”\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "4# predict & metrics\n",
        "y_pred2 = model2.predict(X_test)\n",
        "print(\"MAD:\")\n",
        "print(\"Model 2 (with Age) MAE:\", round(mean_absolute_error(y_test, y_pred2), 3))\n",
        "print(\"Model 1 MAE (with experience):\", round(mean_absolute_error(y_test, y_pred), 3))\n",
        "print(\"RMSE:\")\n",
        "print(\"Model 2 (with Age) RMSE:\", round(np.sqrt(mean_squared_error(y_test, y_pred2)), 3))\n",
        "print(\"Model 1 (with experience) RMSE:\", round(np.sqrt(mean_squared_error(y_test, y_pred)), 3))\n",
        "\n"
      ],
      "metadata": {
        "id": "eccJXQ-i0z5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community ollama scikit-learn pydantic pandas"
      ],
      "metadata": {
        "id": "aI1t1lPjPPmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a clone of my model;\n",
        "\n",
        "import copy\n",
        "\n",
        "model_copy = copy.deepcopy(model)\n"
      ],
      "metadata": {
        "id": "wJLrMkr4PURx"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving teh model _copy\n",
        "import pickle\n",
        "# suppose your fitted model variable is called model2\n",
        "pickle.dump(model_copy, open(\"model_copy.pkl\", \"wb\"))\n"
      ],
      "metadata": {
        "id": "HohIoRxsPZXL"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def predict_age(data_dict):\n",
        "    df = pd.DataFrame([data_dict])\n",
        "    return float(model_copy.predict(df)[0])\n"
      ],
      "metadata": {
        "id": "0YHAcVOOPyyL"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = {\n",
        "  \"Educ\":12,\"South\":0,\"Gender\":0,\"Experience\":30,\"Union\":0,\"Marr\":1,\n",
        "  \"Race_2\":False,\"Race_3\":True,\n",
        "  \"Occup_2\":False,\"Occup_3\":False,\"Occup_4\":False,\"Occup_5\":False,\"Occup_6\":False,\n",
        "  \"Sector_1\":True,\"Sector_2\":False\n",
        "}\n",
        "print(predict_age(example))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoO5ud6UTWRR",
        "outputId": "3cb28710-f531-4a35-c910-f890bf97b11f"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.353646726783758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers accelerate torch"
      ],
      "metadata": {
        "id": "Ng5V1K5mUjnA"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 0) Lightweight, public LLM =====\n",
        "!pip install -q transformers accelerate torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # public & small\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "llm = AutoModelForCausalLM.from_pretrained(MODEL_ID, device_map=\"auto\")\n",
        "gen = pipeline(\"text-generation\", model=llm, tokenizer=tok)\n",
        "\n",
        "def llm_generate(prompt, max_new_tokens=192):\n",
        "    # keep input short to avoid context overflow\n",
        "    enc = tok(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(llm.device)\n",
        "    out = llm.generate(**enc, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "    return tok.decode(out[0], skip_special_tokens=True).strip()\n",
        "\n",
        "# ===== 1) Your sklearn model wrapper =====\n",
        "import pandas as pd\n",
        "\n",
        "model = model_copy  # reuse your trained model in memory\n",
        "\n",
        "FEATURE_ORDER = [\n",
        "    \"Educ\",\"South\",\"Gender\",\"Experience\",\"Union\",\"Marr\",\n",
        "    \"Race_2\",\"Race_3\",\"Occup_2\",\"Occup_3\",\"Occup_4\",\"Occup_5\",\"Occup_6\",\n",
        "    \"Sector_1\",\"Sector_2\"\n",
        "]\n",
        "\n",
        "def predict_from_dict(d: dict) -> float:\n",
        "    row = {}\n",
        "    for k in FEATURE_ORDER:\n",
        "        v = d[k]\n",
        "        if isinstance(v, bool):  # convert booleans to 0/1\n",
        "            v = int(v)\n",
        "        row[k] = v\n",
        "    X = pd.DataFrame([row], columns=FEATURE_ORDER)\n",
        "    return float(model.predict(X)[0])\n",
        "\n",
        "# ===== 2) Tiny, strict schema & robust JSON extraction =====\n",
        "SCHEMA = (\n",
        "    'Return ONLY compact JSON with one of these:\\n'\n",
        "    '{\"action\":\"predict\",\"data\":{FEATURES}}\\n'\n",
        "    '{\"action\":\"update_and_predict\",\"updates\":{FEATURES}}\\n'\n",
        "    'FEATURES keys must be exactly: '\n",
        "    '[\"Educ\",\"South\",\"Gender\",\"Experience\",\"Union\",\"Marr\",\"Race_2\",\"Race_3\",'\n",
        "    '\"Occup_2\",\"Occup_3\",\"Occup_4\",\"Occup_5\",\"Occup_6\",\"Sector_1\",\"Sector_2\"]. '\n",
        "    'Booleans must be true/false, numbers are unquoted.'\n",
        ")\n",
        "\n",
        "import json, re\n",
        "\n",
        "def extract_first_json(text: str) -> dict:\n",
        "    # grab the first {...} block with a simple bracket counter\n",
        "    start = text.find('{')\n",
        "    if start == -1: raise ValueError(f\"No JSON object found. Raw:\\n{text}\")\n",
        "    depth = 0\n",
        "    for i, ch in enumerate(text[start:], start):\n",
        "        if ch == '{': depth += 1\n",
        "        elif ch == '}':\n",
        "            depth -= 1\n",
        "            if depth == 0:\n",
        "                candidate = text[start:i+1]\n",
        "                break\n",
        "    else:\n",
        "        raise ValueError(f\"Incomplete JSON. Raw:\\n{text}\")\n",
        "    # normalize common glitches\n",
        "    candidate = candidate.replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
        "    return json.loads(candidate)\n",
        "\n",
        "# ===== 3) Stateful controller (predict / update_and_predict) =====\n",
        "state = None\n",
        "\n",
        "def controller(user_msg: str):\n",
        "    global state\n",
        "    prompt = (\n",
        "        f\"{SCHEMA}\\n\"\n",
        "        f\"User: {user_msg}\\n\"\n",
        "        f\"Assistant (JSON only):\"\n",
        "    )\n",
        "    raw = llm_generate(prompt)\n",
        "    obj = extract_first_json(raw)\n",
        "\n",
        "    action = obj.get(\"action\")\n",
        "    if action == \"predict\":\n",
        "        data = obj[\"data\"]\n",
        "        # ensure all required keys are present\n",
        "        missing = [k for k in FEATURE_ORDER if k not in data]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Missing keys in data: {missing}\")\n",
        "        state = data.copy()\n",
        "        pred = predict_from_dict(state)\n",
        "        return {\"prediction\": pred, \"state\": state}\n",
        "\n",
        "    elif action == \"update_and_predict\":\n",
        "        if state is None:\n",
        "            raise ValueError(\"No prior state. First do a 'predict' with full data.\")\n",
        "        updates = obj[\"updates\"]\n",
        "        for k, v in updates.items():\n",
        "            if k not in FEATURE_ORDER:\n",
        "                raise ValueError(f\"Unknown feature: {k}\")\n",
        "            state[k] = v\n",
        "        pred = predict_from_dict(state)\n",
        "        return {\"prediction\": pred, \"state\": state}\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown action: {action}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vccTLQL6XEfS",
        "outputId": "fe7139f6-761d-4c2e-8ea3-f46664cdc074"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) First prediction (full row)\n",
        "msg1 = \"\"\"predict for\n",
        "Educ=12, South=0, Gender=0, Experience=23, Union=0, Marr=1,\n",
        "Race_2=false, Race_3=true, Occup_2=false, Occup_3=false, Occup_4=false,\n",
        "Occup_5=false, Occup_6=false, Sector_1=true, Sector_2=false\n",
        "\"\"\"\n",
        "out1 = controller(msg1)\n",
        "print(\"Prediction:\", round(out1[\"prediction\"], 4))\n",
        "print(\"State:\", out1[\"state\"])"
      ],
      "metadata": {
        "id": "QEYJN6mjY82-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y0K5Sdc0Zjhz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}